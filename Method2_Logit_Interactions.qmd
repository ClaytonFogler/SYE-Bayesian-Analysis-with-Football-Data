---
title: "Method2_Logit_Interactions"
author: "Clayton Fogler"
format: html
editor: visual
---


In our first method, we used logistic regression to find our best-fit model for predicting success based on RP, SITUATION, DN, DIST, and PERSONNEL. We found that a logistic Regression Model using DN (Down), DIST (Distance to go), and RP (whether the play was a run or pass) was our best model based on AIC (resulted in an AIC of 1095.1). This model (called logBEST), resulted in a classification rate of 0.632, meaning our model correctly predicted 63.2% of the plays.

Our next method is going to be introducing interaction terms to our models to see if they can yield a higher classification rate.

Just like we did with the original logistic regression models, we will build a model with all our terms that include pairwise interactions for all 5 variables:

```{r}
all_seasons_logit <- all_seasons |>
  mutate(
    RP = factor(RP),
    DN = factor(DN),
    PERSONNEL = factor(PERSONNEL),
    SUCCESSFUL = factor(SUCCESSFUL)
  ) |>
  select(
    SUCCESSFUL, RP, DIST, DN, PERSONNEL
  )
```



```{r}
logALL_inter <- glm(SUCCESSFUL ~ (RP  + DIST + DN + PERSONNEL)^2, data = all_seasons_logit, family = binomial)
summary(logALL_inter)
```

Just like we did with the original logistic regression models, we will use the stepwise function to sort through all of the combinations of our 5 variables to see which interaction model would be the best:


```{r}
logBEST_inter <- step(logALL_inter, direction = "both", trace = FALSE)
summary(logBEST_inter)
BIC(logBEST_inter)
```

*It seems that the best possible model using our 4 variables to predict success, based on AIC and using interaction terms, is a model with RP, DIST,DN, PERSONNEL, and RP:DIST interaction(AIC = 1406, BIC = 1511.134)*

The AIC of our model including interaction (1088.3) was better than the model without interaction (1092.9), but lets see if its classification rate was also better.

```{r}
all_seasons_logit$SUCCESSFUL <- factor(all_seasons_logit$SUCCESSFUL,
                                       levels = c(0, 1),
                                       labels = c("No", "Yes"))

```

glm(formula = SUCCESSFUL \~ RP + DIST + DN + PERSONNEL + RP:DIST,

```{r}
LOGINTERACTION <- train(
  SUCCESSFUL ~ RP + DIST + DN + PERSONNEL + RP*DIST,  # your formula
  data = all_seasons_logit,                 # dataset
  method = "glm",                           # logistic regression
  family = binomial,                        # logistic model
  trControl = trainControl(
    method = "cv",                          # k-fold cross-validation
    number = 5,                             # 5 folds
    savePredictions = "final",              # save predictions for held-out folds
    classProbs = TRUE                       # get predicted probabilities
  )
)

```

```{r}
# Extract cross-validated predictions
cv_preds_int <- LOGINTERACTION$pred

# Convert probability of "Yes" to predicted class
cv_preds_int$pred_class <- ifelse(cv_preds_int$Yes > 0.5, "Yes", "No")

# Actual outcomes
actual_int <- cv_preds_int$obs

# Compute classification rate
classification_rate2 <- mean(cv_preds_int$pred_class == actual_int)
classification_rate2

```

When we added an interaction between RP and DIST, and an interaction between DIST and DN, to our best logistic regression model from method 1, we find a classification rate of 0.627, which means our model correctly predicted 62.7% of the plays. This is better than the model without interaction. What this means is overall, adding in interactions had positive effect to our logistic regression model.

For fun and visualization, we can graph our interaction predicted values based off our logistic regression model:


```{r}

most_common_DN <- names(sort(table(all_seasons_logit$DN), decreasing = TRUE))[1]
most_common_PERSONNEL <- names(sort(table(all_seasons_logit$PERSONNEL), decreasing = TRUE))[1]

dist_values <- sort(unique(all_seasons_logit$DIST))
RP_levels <- levels(all_seasons_logit$RP)

dist_grid <- expand.grid(
  DIST = dist_values,
  RP = RP_levels,
  DN = most_common_DN,
  PERSONNEL = most_common_PERSONNEL
)

# Use caret's predict method
dist_grid$pred_prob <- predict(LOGINTERACTION, newdata = dist_grid, type = "prob")[, "Yes"]

# Plot
ggplot(dist_grid, aes(x = DIST, y = pred_prob, color = RP)) +
  geom_line(size = 1) +
  labs(
    x = "Distance",
    y = "Predicted Probability of Success",
    color = "RP Level",
    title = "Logistic Regression Predicted Probability by DIST and RP (Interaction Model)"
  ) +
  theme_minimal()

```
































```{r}
regression_plot <- all_seasons_logit |>
  mutate(
    pred_probs_inter = pred_probs_inter
  )
```

```{r}
# add facet so its only 1 point per distance

graph_interaction <- ggplot(regression_plot, aes(x = DIST, y = pred_probs_inter, color = RP)) +
  geom_point() + # each predicted observation
  geom_smooth() + # smooth line
  labs(y = "Predicted Probability of Success", x = "Down", color = "Run/Pass") +
  theme_minimal()

graph_logit + graph_interaction
```
